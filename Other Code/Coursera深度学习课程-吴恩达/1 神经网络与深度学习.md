# 神经网络与深度学习

---

- [神经网络与深度学习](#神经网络与深度学习)
  - [第一周](#第一周)
  - [第二周](#第二周)
    - [视频内容](#视频内容)
    - [作业](#作业)
    - [知识点](#知识点)
  - [第三周](#第三周)
    - [视频内容](#视频内容-1)
    - [作业](#作业-1)
  - [第四周](#第四周)



## 第一周
主要讲了神经网络的基本概念、深度学习为什么会兴起以及深度学习的应用等。

## 第二周
### 视频内容
学习如何用神经网络的思维模式提出机器学习问题、如何使用向量化加速你的模型。
- logistics回归算法的概念、损失函数、代价函数、梯度下降训练参数  
- 计算图的概念、前向传播计算输出、反向传播计算导数（链式法则）  
- 向量化避开显示循环、向量化加速运算  
- python的广播机制
### 作业
- **assignment2_1 对Python的简要介绍**
  - 几个函数的numpy实现：sigmoid函数、sigmoid梯度、归一化、softmax函数  
  - numpy矩阵、矢量操作： [numpy.array中各种乘法](https://blog.csdn.net/u011599639/article/details/77926402)
  - python广播机制： [通俗易懂的解释numpy中的广播](https://blog.csdn.net/xiang_freedom/article/details/77968164)
- **assignment2_2 logistics回归分类器来识别猫**
  - 数据预处理：看数据量、展平、归一化  
  - 构建模型：参数初始化函数、前向-后向传播函数（返回参数梯度）、优化函数（迭代更行参数）、预测函数  
  - 数据放入模型：学习、测试  
  
注：assignment2_2 里logistics回归的公式和函数实现要多看看。
### 知识点


## 第三周
### 视频内容
学习使用前向传播和反向传播搭建出有一个隐藏层的神经网络。
- 神经网络表示：组成、符号表示、计算
- 多样本向量化
- 激活函数：常用的激活函数、非线性激活原因、激活函数的导数
- 神经网络的梯度下降
- 随机初始化

### 作业
- **assignment3** 实现一个有一个隐藏层的神经网络。
  - 步骤基本同**assignment2_2**
  - 注意参数的`shape`,
## 第四周
